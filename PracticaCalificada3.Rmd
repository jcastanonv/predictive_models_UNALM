---
title: "Practica Calificada 3"
author: "Jose Castañeda Chilon, Jose Joselito Carhuaricra Cusipuma, Joaquín Antonio Castañón Vilca"
output:
  rmdformats::downcute:
    self_contained: true
    thumbnails: true
    lightbox: true
    gallery: false
    highlight: tango
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```
# Descripción

<div style="text-align: justify"> 
PARTE 1. Indicaciones:
•	Utilice los datos de “diabetes.xlsx” para responder las siguientes preguntas.
•	Semilla 66666
•	Partición 80%-20%
•	Variable target: Outcome

1.	Ejecute una prueba de hipótesis para probar que la variable “Outcome” está balanceada o no.
2.	Calcule la matriz de correlaciones. Interprete. ¿Deben considerarse todas las variables?, ¿Se pueden reducir la dimensionalidad?
3.	Presente un análisis exploratorio de los datos. Tablas y gráficos.
4.	Ejecute la regresión logística para Outcome con la data training.
5.	Presente la matriz de confusión con la data training.
6.	¿Qué variables son significativas? Ejecute la prueba de hipótesis respectiva. Construya intervalos de confianza para los coeficientes de regresión al 97.5%.
7.	Interprete los coeficientes de regresión i y de los exp(i)
8.	Calcule y presente predicciones para los datos de la hoja “predicción” del archivo “diabetes.xlsx”.
9.	Presente la matriz de confusión del ajuste realizado con la data test.
10.	Ejecute la regresión logística con los links: probit, cauchit y cloglog. Presente una tabla comparativa de los valores de la residual deviance. Interprete.

</div>

# Variables
<div style="text-align: justify"> 
**Pregnancies**
**Glucose**
**BloodPressure**
**SkinThickness**
**Insulin**
**BMI**
**DiabetesPedigreeFunction**
**Age**
**Outcome**
</div>

# Librerías utilizadas
<div style="text-align: justify"> 
Las librerías que se van a utilizar para el análisis se presentan a continuación:
</div>
```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
library(ggplot2)
library(dplyr)
library(gridExtra)
library(corrplot)
library(readxl)
library(stats)
library(skimr)
library(FSinR)
library(caret)
library(glm2)
library(tidymodels)
library(Rfast)
```

# Lectura de Datos
```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
diabetes <- read_excel('diabetes.xlsx')
diabetes$Outcome <- factor(diabetes$Outcome)
```

# 1. Prueba de hipótesis para probar que la variable “Outcome” está balanceada
<div style="text-align: justify"> 
se puede usar para probar el nulo de que las proporciones (probabilidades de éxito) en varios grupos son las mismas, o que son iguales a ciertos valores dados:

* $H0:p1=p0$: La hipótesis nula es que la proporción de pacientes diagnosticados con diabetes es la misma proporción real de los que no fueron diagnosticados con diabetes.

* $H1:p1>p0$: La alternativa es que esta proporción sea diferente en al menos una de las poblaciones.
</div>

```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
table(diabetes$Outcome)
plot(table(diabetes$Outcome), 'bar')
```

```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
prop.test(c(500,268), c(768,768))
```
<div style="text-align: justify"> 
Como se puede observar la variable respuesta (*Outcome*) esta claramentes desbalanceada ya que tiene 500 valores $0$ y 268 valores $1$, además la prueba de hipotesis aplicada, dió como resultado un valor-p mucho menor a 0.05 por lo que no se puede aceptar la Hipotesis Nula, por lo tanto es de esperar que las proporciones sean diferentes. 
Concluyendose que esta base de datos se encuentra desbalanceada, lo cual puede afectar en el desarrollo de los modelos más adelante.
</div>
# 2.	Matriz de Correlaciones
## ¿Deben considerarse todas las variables?, ¿Se pueden reducir la dimensionalidad?
```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
colnames(diabetes)
numeric.var <- sapply(diabetes, is.numeric)
corr.matrix <- cor(diabetes[,numeric.var])
corrplot(corr.matrix, main="\n\nCorrelation Plot for Numerical Variables", order = "hclust", tl.col = "black", tl.srt=45, tl.cex=0.5, cl.cex=0.5)
```

```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
colnames(diabetes)
numeric.var <- sapply(diabetes, is.numeric)
corr.matrix <- cor(diabetes[,numeric.var])
corr.matrix
```

<div style="text-align: justify"> 
Existe una baja correlación entre las variables, de las cuales las que tienen una correlación de Pearson más fuerte son: Age, Insulin, SkinThickness, BMI y Pregnancies.
</div>

<div style="text-align: justify"> 
Se puede realizar un análisis para la reducción de dimensiones ya que se tienen algunas variables con baja correlación, a continuación se realizará dos test para ver la significancia de cada varaible independiente sobre la varaible respuesta.
</div>
```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
set.seed(66666)
algo_search_hill <- searchAlgorithm(searcher = 'hillClimbing')
algo_eval_bina <- filterEvaluator(filter = 'binaryConsistency')
result <- featureSelection(diabetes, 'Outcome', algo_search_hill, algo_eval_bina)
print(cbind(result[c('evaluationMethod', 'searchMethod')]))
print(result$bestFeatures)
```
<div style="text-align: justify"> 
Como se puede observar, con la prueba aplicada, se pueden utilziar las variables: *Pregnancies, Glucose, SkinThickness y Age*, como aquellas variables suficientes para realizar una clasificación, es decir, detectar si un paciente tiene diabetes o no.
</div>
# 3.	Presente un análisis exploratorio de los datos. Tablas y gráficos.

```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
head(diabetes)
```

```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
dim(diabetes)
str(diabetes)
```

```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
skim(diabetes)
cat("Valores nulos en la base de datos:", sum(is.na(diabetes)), "\n")
summary(diabetes)
```

```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
summary(diabetes)
```

```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
p1 <- ggplot(diabetes, aes(x=Pregnancies)) + ggtitle("Number of times pregnant") +
  geom_histogram(aes(y = 100*(..count..)/sum(..count..)), binwidth = 1, colour="black", fill="white") + ylab("Percentage")
p2 <- ggplot(diabetes, aes(x=Glucose)) + ggtitle("Glucose") +
  geom_histogram(aes(y = 100*(..count..)/sum(..count..)), binwidth = 5, colour="black", fill="white") + ylab("Percentage")
p3 <- ggplot(diabetes, aes(x=BloodPressure)) + ggtitle("Blood Pressure") +
  geom_histogram(aes(y = 100*(..count..)/sum(..count..)), binwidth = 2, colour="black", fill="white") + ylab("Percentage")
p4 <- ggplot(diabetes, aes(x=SkinThickness)) + ggtitle("Skin Thickness") +
  geom_histogram(aes(y = 100*(..count..)/sum(..count..)), binwidth = 2, colour="black", fill="white") + ylab("Percentage")
p5 <- ggplot(diabetes, aes(x=Insulin)) + ggtitle("Insulin") +
  geom_histogram(aes(y = 100*(..count..)/sum(..count..)), binwidth = 20, colour="black", fill="white") + ylab("Percentage")
p6 <- ggplot(diabetes, aes(x=BMI)) + ggtitle("Body Mass Index") +
  geom_histogram(aes(y = 100*(..count..)/sum(..count..)), binwidth = 1, colour="black", fill="white") + ylab("Percentage")
p7 <- ggplot(diabetes, aes(x=DiabetesPedigreeFunction)) + ggtitle("Diabetes Pedigree Function") +
  geom_histogram(aes(y = 100*(..count..)/sum(..count..)), colour="black", fill="white") + ylab("Percentage")
p8 <- ggplot(diabetes, aes(x=Age)) + ggtitle("Age") +
  geom_histogram(aes(y = 100*(..count..)/sum(..count..)), binwidth=1, colour="black", fill="white") + ylab("Percentage")
grid.arrange(p1, p2, p3, p4, p5, p6, p7, p8, ncol=2)
```

```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
attach(diabetes)
par(mfrow=c(2,4))
boxplot(Pregnancies~Outcome, main="No. of Pregnancies vs. Diabetes", 
        xlab="Outcome", ylab="Pregnancies")
boxplot(Glucose~Outcome, main="Glucose vs. Diabetes", 
        xlab="Outcome", ylab="Glucose")
boxplot(BloodPressure~Outcome, main="Blood Pressure vs. Diabetes", 
        xlab="Outcome", ylab="Blood Pressure")
boxplot(SkinThickness~Outcome, main="Skin Thickness vs. Diabetes", 
        xlab="Outcome", ylab="Skin Thickness")
boxplot(Insulin~Outcome, main="Insulin vs. Diabetes", 
        xlab="Outcome", ylab="Insulin")
boxplot(BMI~Outcome, main="BMI vs. Diabetes", 
        xlab="Outcome", ylab="BMI")
boxplot(DiabetesPedigreeFunction~Outcome, main="Diabetes Pedigree Function vs. Diabetes", xlab="Outcome", ylab="DiabetesPedigreeFunction")
boxplot(Age~Outcome, main="Age vs. Diabetes", 
        xlab="Outcome", ylab="Age")
par(mfrow=c(1,1))
```

# 4.	Ejecute la regresión logística para Outcome con la data training
## Separando los datos en training y testing
```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
set.seed(66666)
trainIndex <- createDataPartition(diabetes$Outcome, p = .8,
                                  list = FALSE,
                                  times = 1)
diabetes_train <- diabetes[ trainIndex,]
diabetes_test <- diabetes[-trainIndex,]
```
<div style="text-align: justify"> 
Después de la separación de los datos de training y testing, se obtuvo que para el entramiento se tiene 615 observaciones mientras que para testing se tendra 153, sumando en total las 768 observaciones de la base original.
</div>

```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
print(length(diabetes_train$Outcome))
print(length(diabetes_test$Outcome))
```
## Ejecutando una regresión logística con el training
```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
model <-glm(Outcome ~.,family=binomial(link='logit'),data=diabetes_train)
```

# 5.	Presente la matriz de confusión con la data training
<div style="text-align: justify"> 
El modelo presento los siguientes resultados predecidos para los datos training:
</div>
```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
diabetes_train$ClassPredicted <- predict(model,newdata=diabetes_train, 'response')
head(diabetes_train[, c('Outcome', 'ClassPredicted')])
```
<div style="text-align: justify"> 
O también se pueden observar de la siguiente manera:
</div>
```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
diabetes_train$ClassPredicted <- round(predict(model,newdata=diabetes_train, 'response'),0)
head(diabetes_train[, c('Outcome', 'ClassPredicted')])
```

<div style="text-align: justify"> 
Lo que genera la siguiente matriz de confusión:
</div>
```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
table(diabetes_train$Outcome, diabetes_train$ClassPredicted)
```
<div style="text-align: justify"> 
Teniendo una precisión de 0.79, como se muestra
</div>
```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
fitted.results <- predict(model,newdata=diabetes_train,type='response')
fitted.results <- ifelse(fitted.results > 0.5,1,0)
misClasificError <- mean(fitted.results != diabetes_train$Outcome)
print(paste('Accuracy',1-round(misClasificError, 2)))
```

# 6.	¿Qué variables son significativas? Ejecute la prueba de hipótesis respectiva. Construya intervalos de confianza para los coeficientes de regresión al 97.5%
## Significancia del modelo
```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
summary(model)
```
<div style="text-align: justify"> 
Como se puede observar la varaible *Pregnancies, Glucose, BloodPressure, BMI y DiabetesPedigreeFunction*, son las varaibles más significativas para el modelo. Dado que el valor-p de cada uno de los coeficientes mencionados son menores a 0.05.
</div>

```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
anova(model, test="Chisq")
```

## Intervalos de confianza
```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
for (var in c(colnames(diabetes[,1:8]))){
  print(var)
  print(confint(model, var, 0.95))
}
```

# 7.	Interprete los coeficientes de regresión $ßi$ y de los exp($ßi$)
```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
exp(coef(model))
```
<div style="text-align: justify"> 
Dado que las siguientes variables son las significativas: *Pregnancies, Glucose, BloodPressure, BMI y DiabetesPedigreeFunction*, se puede decir que la presencia de Pregnancies o embarazo, incrementa las probabilidades de que genere diabetes en 1.13 veces más, la Glucosa en 1.03, el BMI en 1.10 y por ultimo Diabetes Pedigree Function incrementa 3.24 veces más las probabilidades de ser diagnosticado con diabetes. Mientra que BloodPressure o presión arterial tiende a disminuir 0.98 veces cuando este disminuye.
</div>

# 8.	Calcule y presente predicciones de datos
<div style="text-align: justify"> 
A continuación, se presentan los resultado de las predicciones para la clasificación de datos nuevos.
</div>
```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
diabetes_pred <- read_excel('diabetes.xlsx', sheet = 'predicción')
diabetes_pred$ClassPredicted <- round(predict(model,newdata=diabetes_pred, 'response'),0)
diabetes_pred
```

# 9.	Presente la matriz de confusión del ajuste realizado con la data test.
```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
diabetes_pred <- read_excel('diabetes.xlsx', sheet = 'predicción')
diabetes_pred$ClassPredicted <- round(predict(model,newdata=diabetes_pred, 'response'),0)
diabetes_pred
```
<div style="text-align: justify"> 
Con una precisión de 0.77:
</div>
```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
fitted.results <- predict(model,newdata=diabetes_test,type='response')
fitted.results <- ifelse(fitted.results > 0.5,1,0)
misClasificError <- mean(fitted.results != diabetes_test$Outcome)
print(paste('Accuracy',1-round(misClasificError, 2)))
```

# 10.	Ejecute la regresión logística con los links: probit, cauchit y cloglog. Presente una tabla comparativa de los valores de la residual deviance. Interprete.
<div style="text-align: justify"> 
Como se puede observar, cloglog tienes un residual deviance de 573.8 siendo superior al resto de valores mientras, que logit tiene la menor deviance, con este ultimo se desarrollo el modelo para responder todas las preguntas anteriores
</div>
```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
model_probit <-glm(Outcome ~.,family=binomial(link='probit'),data=diabetes_train)
model_cauchit <-glm(Outcome ~.,family=binomial(link='cauchit'),data=diabetes_train)
model_cloglog <-glm2(Outcome ~.,family=binomial(link='cloglog'),data=diabetes_train)

matrix(c('logit','probit', 'cauchit', 'cloglog', model$deviance, model_probit$deviance, model_cauchit$deviance, model_cloglog$deviance), 4,2)
```





# Descripción

<div style="text-align: justify"> 
PARTE 2. Indicaciones:
•	Utilice los datos de “diabetes.xlsx” para responder las siguientes preguntas.
•	Semilla 987654321
•	Partición 80%-20%
•	Variable target: Pregnancies


1.	Pruebe la hipótesis de que la variable “Pregnancies” tiene distribución Poisson con la función poisdisp.test
2.	Ejecute la regresión poisson para Pregnancies con la data training.
3.	Aplique 10-fold cross validation para calcular el valor de MSE con la data training.
4.	¿Qué variables son significativas? Ejecute la prueba de hipótesis respectiva. Construya intervalos de confianza para los coeficientes de regresión al 97.5%.
5.	Ejecute la regresión binomial negativa para Pregnancies con la data training.
6.	Presente la MSE con la data training del punto (5)
7.	Ejecute la regresión inflada de ceros y compare con los resultados obtenidos en (3) y (4).
8.	Ejecute la regresión hurdle y compare con los resultados obtenidos en (3), (4) y (5).

</div>

# Variables
<div style="text-align: justify"> 
**Pregnancies**
**Glucose**
**BloodPressure**
**SkinThickness**
**Insulin**
**BMI**
**DiabetesPedigreeFunction**
**Age**
**Outcome**
</div>

# Librerías
```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
library(Rfast)
library(readxl)
library(tidyverse)
library(tidymodels)  
library(AER)
require(sandwich)
require(msm)
library(caret)
library(boot)
require("MASS")
library(pscl)
```

# Lectura de Datos
```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
bd_diabetes<-read_excel("diabetes.xlsx")
```

# Separación de data : Entrenamiento (0.8) y prueba (0.2)

```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
set.seed(987654321)

bd_diabetes %>% initial_split(prop = 0.80, strata =  Pregnancies) -> division

division %>% training() -> training_set

division %>% testing() -> testing_set

bd_diabetes %>% nrow();training_set %>% nrow();testing_set %>% nrow()
```


# Desarrollo de Preguntas

#1.Pruebe la hipótesis de que la variable “Pregnancies” tiene distribución Poisson con la función poisdisp.test

<div style="text-align: justify"> 
Representación gráfica de la variable Target "Pregnancies
</div>

```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
par(mfrow=c(1,2))
str(bd_diabetes)
hist(as.numeric(bd_diabetes$Pregnancies), xlab = "Pregnancies", ylab = "Frecuencia", las=1, main = "", col = "gray")
plot(density(as.numeric(bd_diabetes$Pregnancies)), xlab = "Pregnancies", ylab = "Densidad", las=1, main = "")

```
<div style="text-align: justify"> 

Interpretación :Gráficamente se puede apreciar que la variable "Pregnancies" tiene
gran acumulación de ceros en sus resultados. En este sentido, se puede decir que los datos 
muestran una distribución asimétrica con sesgo positivo.
</div>

<div style="text-align: justify"> 
Prueba de hipótesis distribución Poisson

* $H0$: el número de mujeres embarazadas en un espacio de tiempo sigue una distribución Poisson.

* $H1$: el número de mujeres embarazadas en un espacio de tiempo  no sigue una distribución Poisson.
</div>

```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
res1<-pois.test(bd_diabetes$Pregnancies)
res1
```

<div style="text-align: justify"> 
Interpretación: A un nivel de 0.05 existe evidencia para rechazar la hipótesis nula.
En este sentido, la variable "Pregnancies" no sigue una distribución de poisson.
</div>

<div style="text-align: justify"> 
Prueba de hipótesis para la dispersión presente en los valores

* $H0$: La variable "Pregnancies" no presenta dispersión.

* $H1$: La variable "Pregnancies" presenta alta/baja dispersión.

</div>


```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
res2<-poisdisp.test(as.numeric(bd_diabetes$Pregnancies),"over",logged = FALSE)
res2
```

<div style="text-align: justify"> 

Interpretación: A un nivel de 0.05 existe evidencia para rechazar la hipótesis nula.
En este sentido, la variable "Pregnancies" presenta sobre dispersión. Ello se
puede asociar a la canidad de ceros existente.

</div>

#2.Ejecute la regresión poisson para Pregnancies con la data training.


```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
m1 <- glm(as.numeric(Pregnancies) ~., family="poisson", data=training_set)
m1
```

<div style="text-align: justify"> 

Para realizar una prueba de  bondad de ajuste para el modelo general podemos hacer uso de lo resultados de Desvianza


Prueba de hipótesis bondad de ajuste

* $H0$: El modelo de Poisson es apropiado.

* $H1$: El modelo de Poisson no es apropiado
</div>

```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
with(m1, cbind(res.deviance = deviance, df = df.residual,
               p = pchisq(deviance, df.residual, lower.tail=FALSE)))
```

<div style="text-align: justify"> 
Interpretación : A un nivel de significancia del 0.05 se rechaza la Ho.
Es decir, el modelo Poisson no es apropiado,
</div>

#3. Aplique 10-fold cross validation para calcular el valor de MSE con la data training.

<div style="text-align: justify"> 
Se emplea la función cv.glm() para la validación, empleando en este caso k=10
</div>

```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
set.seed(1)
cv_error <- cv.glm(data = training_set, glmfit =m1 , K = 10)
cv_error$delta

```

<div style="text-align: justify">
La estimación de error del modelo lineal mediante K-fold Cross-Validation k=10 es de 9.490342 (MSE corregido)
</div>


#4.¿Qué variables son significativas? Ejecute la prueba de hipótesis respectiva. 

```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
summary(m1 <- glm(Pregnancies ~., family="poisson", data=training_set))
```

<div style="text-align: justify">

Interpretación: A un nivel de significancia de 0,05 las variables significativas para el modelo son *DiabetesPedigreeFunction,Age Outcome*                   

</div>

#5. Ejecute la regresión binomial negativa para Pregnancies con la data training.


```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
m2 <- glm.nb( Pregnancies~ ., data =training_set )
```


<div style="text-align: justify"> 

Para realizar una prueba de  bondad de ajuste para el modelo general podemos hacer uso de lo resultados de Desvianza


Prueba de hipótesis bondad de ajuste

* $H0$: El modelo de Binomial Negativa es apropiado.

* $H1$: El modelo de Binomial Negativa no es apropiado
</div>

```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
with(m2, cbind(res.deviance = deviance, df = df.residual,
               p = pchisq(deviance, df.residual, lower.tail=FALSE)))
```

<div style="text-align: justify"> 
Interpretación : A un nivel de significancia del 0.05 se rechaza la Ho.
Es decir, el modelo Binomial Negativa  no es apropiado, 
</div>

#6.	Presente la MSE con la data training del punto (5)

Se emplea la función cv.glm() para la validación, empleando en este caso k=10


```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
set.seed(1)
cv_error2 <- cv.glm(data = training_set, glmfit =m2 , K = 10)
cv_error2$delta
```

<div style="text-align: justify">
La estimación de error del modelo  de regresión "binomial negativa" mediante K-fold Cross-Validation k=10 es de 11.19859 (MSE corregido)
</div>

#7.Ejecute la regresión inflada de ceros y compare con los resultados obtenidos anteriormente

```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
m3<-zeroinfl(Pregnancies ~ ., data =training_set , dist = "negbin")

cv_error3 <- cv.glm(data = training_set, glmfit =m3 , K = 10)
cv_error3$delta

```

<div style="text-align: justify">
La estimación de error del modelo "zeroinfl" mediante K-fold Cross-Validation k=10 es de 9.980023 (MSE corregido)
</div>

#8.Ejecute la regresión hurdle y compare con los resultados obtenidos.


```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
cv_error4 <- cv.glm(data = training_set, glmfit =m3 , K = 10)
cv_error4$delta

```

<div style="text-align: justify">
La estimación de error del modelo "hurdle" mediante K-fold Cross-Validation k=10 es de 9.963759 (MSE corregido)
</div>



#9 Comparación de MSE de los 4 modelos analizados bajo la metodología K-fold validación cruzada

```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
res_MSE <- data.frame(
  "Modelo" = c("Poisson", "Binomial Negativo", "Cero_Inflados", "Hurdle"), 
  "MSE" = c(cv_error$delta[[2]],cv_error2$delta[[2]],cv_error3$delta[[2]]
               ,cv_error4$delta[[2]]))

res_MSE
```

Podemos apreciar que el modelo Binomial Negativo presenta un mayor MSE y el de Hurdle el menor. En este sentido, este último tiene mejor desempeño debido a su menor nivel de error.

# Descripción

<div style="text-align: justify"> 
Parte 3:

•	Utilice los datos de “coalition” de la librería Zileg para responder las siguientes preguntas.
o	install.packages("Zelig")
o	library(Zelig)
o	data(coalition)
•	Semilla 22222222
•	Partición 80%-20%
•	Variable target: duration

1.	Pruebe la bondad de ajuste de la variable “duration” a la distribución gamma con el Package ‘goft’
2.	Calcule la matriz de correlaciones. Interprete. ¿Deben considerarse todas las variables?, ¿Se pueden reducir la dimensionalidad?
3.	Presente un análisis exploratorio de los datos. Tablas y gráficos.
4.	Ejecute la regresión gamma para “duration” con la data training. Use glm y glm.fit2. Compare sus resultados.
5.	Aplique 10-fold cross validation para calcular el valor de MSE con la data training.
6.	Presente la MSE con la data training.
7.	¿Qué variables son significativas? Ejecute la prueba de hipótesis respectiva. Construya intervalos de confianza para los coeficientes de regresión al 96.5%.
8.	Calcule y presente predicciones para los datos de la hoja “predicción” del archivo “coalition.xlsx”.
9.	Presente la MSE del ajuste realizado con la data test.
10.	Ejecute la regresión gamma e inversa gaussiana con los links disponibles en R. Interprete. Presente una tabla comparativa de los valores de la residual deviance.
</div>


# Lectura de Datos
```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
library(readxl)
datos<-read_xlsx('coalition.xlsx',sheet = "coalition")
```

# Desarrollo de Preguntas

# 1. # Pruebe la bondad de ajuste de la variable “duration” a la distribución gamma con el Package ‘goft’

```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
modelo1<-glm(formula = datos$duration~datos$ciep12+datos$invest+datos$fract+datos$polar+datos$numst2+datos$crisis,family = Gamma(link = "inverse"),x = TRUE)
summary.glm(modelo1)
```

#2. Calcule la matriz de correlaciones. Interprete. ¿Deben considerarse todas las variables? ¿Se pueden reducir la dimensionalidad?


```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
cor(datos)
```

<div style="text-align: justify"> 
De los resultados observamos que la correlación mas debil esta entre duration versus crisis con solo 0.036, con las otras variables la correlación esta entre 0.207 (numst2) hasta -0.72 con la variable ciep12.
</div>
#3. Presente un análisis exploratorio de los datos. Tablas y gráficos
```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
summary(datos)
par(mfrow=c(1,1))
hist(datos$duration)
```

<div style="text-align: justify">
Para la variable duration el valor minimo es 0.5, el primer cuartil es 6.0, la mediana es 14.0, la media es 18.44, el tercer cuartil es 28.0 y el valor maximo es 59.0
Para la variable ciep12 el valor minimo es 0.0, el primer cuartil es 1.0, la mediana es 1.0, la media es 0.86, el tercer cuartil es 1.0 y el valor maximo es 1.0
Para la variable invest el valor minimo es 0.0, el primer cuartil es 0.0, la mediana es 0.0, la media es 0.45, el tercer cuartil es 1.0 y el valor maximo es 1.0
Para la variable fract el valor minimo es 349, el primer cuartil es 677, la mediana es 719, la media es 718.8, el tercer cuartil es 788 y el valor maximo es 868
Para la variable polar el valor minimo es 0.0, el primer cuartil es 3.0, la mediana es 14.5, la media es 15.29, el tercer cuartil es 25.0 y el valor maximo es 43.0
Para la variable numst2 el valor minimo es 0.0, el primer cuartil es 0.0, la mediana es 1.0, la media es 0.63, el tercer cuartil es 1.0 y el valor maximo es 1.0
Para la variable crisis el valor minimo es 0.0, el primer cuartil es 0.0, la mediana es 10.0, la media es 22.38, el tercer cuartil es 29.75 y el valor maximo es 274.0
</div>

```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
par(mfrow=c(3,1))
hist(datos$fract)
hist(datos$polar)
hist(datos$crisis)
table(datos$ciep12)
table(datos$invest)
table(datos$numst2)
par(mfrow=c(1,1))
```


#4. # Ejecute la regresión gamma para “duration” con la data training. Use glm 

```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
modelo1<-glm(formula = datos$duration~datos$ciep12+datos$invest+datos$fract+datos$polar+datos$numst2+datos$crisis,family = Gamma(link = "inverse"),x = TRUE)
modelo1$coefficients
```

```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
library(glm2)
modelo2<-glm.fit2(datos[,-1],datos$duration,family=Gamma("identity"))
modelo2$coefficients
```

<div style="text-align: justify">
Vemos que en el modelo 1 existe el termino independiente 3.01 mientras que en el modelo 2 no existe.
Para la variables ciep12 el valor en modelo1 es 3.31e-02 en el modelo2 es -11.78
Para la variables invest el valor en modelo1 es 6.85e-03 en el modelo2 es 0.59
Para la variables fract el valor en modelo1 es -1.12e-05 en el modelo2 es 0.04
Para la variables polar el valor en modelo1 es 1.42e-03 en el modelo2 es -0.43
Para la variables numst2 el valor en modelo1 es -9.88e-03 en el modelo2 es 4.80
Para la variables crisis el valor en modelo1 es -9.77e-06 en el modelo2 es 0.08
</div>

#5. Aplique 10-fold cross validation para calcular el valor de MSE con la data training.


```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
library(caret)
set.seed(22222222)
inTraining <- createDataPartition(datos$duration, p = .80,list = FALSE)
training <- datos[inTraining,]
testing  <- datos[-inTraining,]
fitControl <- trainControl(method = "repeatedcv",number = 10,repeats = 10)
knn.datos <- train(duration~.,data = datos,method = 'knn',trControl = fitControl)
```

#6.	# Presente la MSE con la data training

```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
knn.datos
plot(knn.datos)
```

#7.¿Qué variables son significativas? Ejecute la prueba de hipótesis respectiva.

```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
summary.glm(modelo1)
```

<div style="text-align: justify">
Para alpha=0.05:

* Ho: El coeficiente no es significativo

* H1: El coeficiente es significativo

Intercept: p=0.03<0.05 aceptamos H1, el coeficiente es significativo
ciep12: p=0.0<0.05 aceptamos H1, el coeficiente es significativo
invest: p=0.1591>0.05 aceptamos Ho, el coeficiente no es significativo
fract: p=0.5912>0.05 aceptamos Ho, el coeficiente no es significativo
polar: p=0.0<0.05 aceptamos H1, el coeficiente es significativo
numst2: p=0.050>0.05 aceptamos Ho, el coeficiente no es significativo
crisis: p=0.78>0.05 aceptamos Ho, el coeficiente no es significativo
</div>

#8. # Calcule y presente predicciones para los datos de la hoja “predicción” del archivo “coalition.xlsx


```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
newdata1<-read_xlsx("coalition.xlsx",sheet = "predicción_gamma")
str(newdata1)
predict.glm(modelo1,newdata1,se.fit =T)
```

#9. Presente la MSE del ajuste realizado con la data test.

```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
deviance(modelo1)
```
El MSE del ajuste realizado con la dataset es 208.1815

#10.  Ejecute la regresión gamma e inversa gaussiana
## Regresion gamma
```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
modelo1<-glm(formula = datos$duration~datos$ciep12+datos$invest+datos$fract+datos$polar+datos$numst2+datos$crisis,family = Gamma(link = "inverse"),x = TRUE)
modelo1
```
## Regresion inversa
```{r echo=TRUE, fig.show='hold', message=FALSE, warning=FALSE}
modelo3<-glm2(datos$duration~datos$ciep12+datos$invest+datos$fract+datos$polar+datos$numst2+datos$crisis, data=datos, family=inverse.gaussian(link = "1/mu^2"),maxit=10)
modelo3
```
Con el modelo de regresión gamma la devianza es 208.2
Con el modelo de regresión inversa gaussiana la devianza es 42.05








